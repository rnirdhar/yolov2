{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ff6421d3057bd82e33133d3787cf3c279ad6454"
      },
      "cell_type": "code",
      "source": "!mkdir yolo",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d649b4891925d63da9f0c51b285360d7182c649"
      },
      "cell_type": "code",
      "source": "! cp -r ../input/keras-yolo-blood/keras_yolo2_blood/keras_yolo2_blood/ /kaggle/working/yolo",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5200b1ee204e7eac9334d7a816ff770c9a160885"
      },
      "cell_type": "code",
      "source": "!cp -r ../input/bccdcells/bccd/bccd/ /kaggle/working/yolo/keras_yolo2_blood/\n#!cp -r ../input/pascal-voc-dataset/mxnetdata/mxnetdata/VOC2007 /kaggle/working/yolo/keras-yolo2/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b45989b2548e916cf7935d5fc6ebd2e38135c10e"
      },
      "cell_type": "code",
      "source": "!cp -r ../input/yoloweight/yolov2.weights /kaggle/working/yolo/keras_yolo2_blood/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07c0e1f3b4f928bb6e071c8d3fbd0e38a1c28aa7"
      },
      "cell_type": "code",
      "source": "%cd /kaggle/working/yolo/keras_yolo2_blood/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0aa83fdd05fd81562835bb05f3222ab1b6c38d12"
      },
      "cell_type": "code",
      "source": "#!rm -r /kaggle/working/yolo/keras_yolo2_blood/full_yolo_backend.h5",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bceb0e47eb3100c4f3f77fad03f7c45ba4cdccc1"
      },
      "cell_type": "code",
      "source": "!python train.py --conf config.json",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:12.050840Z",
          "start_time": "2017-11-30T13:01:12.032017Z"
        },
        "code_folding": [],
        "scrolled": true,
        "trusted": true,
        "_uuid": "5f05b4c5887dad35c8ac75cc7823333297cacc84"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential, Model\nfrom keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\nfrom keras.optimizers import SGD, Adam, RMSprop\nfrom keras.layers.merge import concatenate\nimport matplotlib.pyplot as plt\nimport keras.backend as K\nimport tensorflow as tf\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm_notebook\nimport numpy as np\nimport json\nimport pickle\nimport os, cv2\nfrom preprocessing import parse_annotation, BatchGenerator\nfrom utils import WeightReader, decode_netout, draw_boxes\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66475f1cac1b17e5366aeb4e21ab0ff278c57feb"
      },
      "cell_type": "code",
      "source": "image_path = './bccd/JPEGImages/'\nannot_path = './bccd/Annotations/'\n\nall_imgs, seen_labels = parse_annotation(annot_path, image_path)\nmax_box_per_image = max([len(inst['object']) for inst in (all_imgs)])\nmax_box_per_image",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T12:56:03.960420Z",
          "start_time": "2017-11-30T12:56:03.943536Z"
        },
        "scrolled": true,
        "trusted": true,
        "_uuid": "5264323ebbf869b065128b7f1b8851b20fc30f32"
      },
      "cell_type": "code",
      "source": "#LABELS = [\"car\",\"person\",\"chair\",\"bird\"]\nLABELS = [\"Platelets\", \"RBC\", \"WBC\"]\nIMAGE_H, IMAGE_W = 416, 416\nGRID_H,  GRID_W  = 13 , 13\nBOX              = 5\nCLASS            = len(LABELS)\nCLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\nOBJ_THRESHOLD    = 0.3\nNMS_THRESHOLD    = 0.3\nANCHORS          = [0.81,1.04, 1.77,2.64, 2.20,2.43, 2.35,3.06, 4.33,5.22]\n\nNO_OBJECT_SCALE  = 1.0\nOBJECT_SCALE     = 5.0\nCOORD_SCALE      = 3.0\nCLASS_SCALE      = 3.0\n\nBATCH_SIZE       = 32\nWARM_UP_BATCHES  = 3\nTRUE_BOX_BUFFER  = max_box_per_image",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T12:56:07.205941Z",
          "start_time": "2017-11-30T12:56:07.200546Z"
        },
        "trusted": true,
        "_uuid": "f80e48e354ecbc2dd7069be282c34085a3e9a4fb"
      },
      "cell_type": "code",
      "source": "wt_path = './yolov2.weights'                      ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T12:56:40.189135Z",
          "start_time": "2017-11-30T12:56:40.181109Z"
        },
        "trusted": true,
        "_uuid": "2251df130d3834ef77b8d5862ac513292b804704"
      },
      "cell_type": "code",
      "source": "generator_config = {\n    'IMAGE_H'         : IMAGE_H, \n    'IMAGE_W'         : IMAGE_W,\n    'GRID_H'          : GRID_H,  \n    'GRID_W'          : GRID_W,\n    'BOX'             : BOX,\n    'LABELS'          : LABELS,\n    'CLASS'           : len(LABELS),\n    'ANCHORS'         : ANCHORS,\n    'BATCH_SIZE'      : BATCH_SIZE,\n    'TRUE_BOX_BUFFER' : max_box_per_image,\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b668c191c33f0fb6208886b1733e6b6fec686b92"
      },
      "cell_type": "code",
      "source": "seen_labels",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T12:57:54.884337Z",
          "start_time": "2017-11-30T12:57:54.875537Z"
        },
        "trusted": true,
        "_uuid": "312e3b01e63b4b8a963524042e9a39d6a9836bed"
      },
      "cell_type": "code",
      "source": "batches = BatchGenerator(all_imgs, generator_config)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:00:49.858239Z",
          "start_time": "2017-11-30T13:00:48.622400Z"
        },
        "scrolled": true,
        "trusted": true,
        "_uuid": "461d55d254f826b2b7564fe097148f96dd374275"
      },
      "cell_type": "code",
      "source": "image = batches[0][0][0][0]\nplt.imshow(image.astype('uint8'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a70f506afbc4f2ef528ba40aa48470a1645e4ee"
      },
      "cell_type": "code",
      "source": "def normalize(image):\n    return image/255.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:23.813647Z",
          "start_time": "2017-11-30T13:01:23.806527Z"
        },
        "trusted": true,
        "_uuid": "93245ab588f4c56b479dc9c110d2492fa54516ac"
      },
      "cell_type": "code",
      "source": "train_valid_split = int(0.8*len(all_imgs))\n\ntrain_batch = BatchGenerator(all_imgs[:train_valid_split],generator_config, norm=normalize)\nvalid_batch = BatchGenerator(all_imgs[train_valid_split:], generator_config, norm=normalize)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d971a1d01b8638d421bb2d859a03c0a8c9eca2d4"
      },
      "cell_type": "code",
      "source": "len(train_batch[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02b7cfc47f007ec71fa76bc4060d3c2eb2f70af5"
      },
      "cell_type": "markdown",
      "source": "# Construct the network"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:25.787710Z",
          "start_time": "2017-11-30T13:01:25.783454Z"
        },
        "trusted": true,
        "_uuid": "24eddab8941155d2e40212be65c168f9852b5364"
      },
      "cell_type": "code",
      "source": "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\ndef space_to_depth_x2(x):\n    return tf.space_to_depth(x, block_size=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:27.879909Z",
          "start_time": "2017-11-30T13:01:26.516327Z"
        },
        "code_folding": [],
        "trusted": true,
        "_uuid": "367ec82ec2ec49bb4770da67ba670f3d3cb2aa13"
      },
      "cell_type": "code",
      "source": "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\ntrue_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n\n# Layer 1\nx = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\nx = BatchNormalization(name='norm_1')(x)\nx = LeakyReLU(alpha=0.1)(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Layer 2\nx = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\nx = BatchNormalization(name='norm_2')(x)\nx = LeakyReLU(alpha=0.1)(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Layer 3\nx = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\nx = BatchNormalization(name='norm_3')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 4\nx = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\nx = BatchNormalization(name='norm_4')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 5\nx = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\nx = BatchNormalization(name='norm_5')(x)\nx = LeakyReLU(alpha=0.1)(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Layer 6\nx = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\nx = BatchNormalization(name='norm_6')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 7\nx = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\nx = BatchNormalization(name='norm_7')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 8\nx = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False, input_shape=(416,416,3))(x)\nx = BatchNormalization(name='norm_8')(x)\nx = LeakyReLU(alpha=0.1)(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Layer 9\nx = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\nx = BatchNormalization(name='norm_9')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 10\nx = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\nx = BatchNormalization(name='norm_10')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 11\nx = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\nx = BatchNormalization(name='norm_11')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 12\nx = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\nx = BatchNormalization(name='norm_12')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 13\nx = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\nx = BatchNormalization(name='norm_13')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\nskip_connection = x\n\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Layer 14\nx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\nx = BatchNormalization(name='norm_14')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 15\nx = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\nx = BatchNormalization(name='norm_15')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 16\nx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\nx = BatchNormalization(name='norm_16')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 17\nx = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\nx = BatchNormalization(name='norm_17')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 18\nx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\nx = BatchNormalization(name='norm_18')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 19\nx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\nx = BatchNormalization(name='norm_19')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 20\nx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\nx = BatchNormalization(name='norm_20')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 21\nskip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\nskip_connection = BatchNormalization(name='norm_21')(skip_connection)\nskip_connection = LeakyReLU(alpha=0.1)(skip_connection)\nskip_connection = Lambda(space_to_depth_x2)(skip_connection)\n\nx = concatenate([skip_connection, x])\n\n# Layer 22\nx = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\nx = BatchNormalization(name='norm_22')(x)\nx = LeakyReLU(alpha=0.1)(x)\n\n# Layer 23\nx = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\noutput = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n\n# small hack to allow true_boxes to be registered when Keras build the model \n# for more information: https://github.com/fchollet/keras/issues/2790\noutput = Lambda(lambda args: args[0])([output, true_boxes])\n\nmodel = Model([input_image, true_boxes], output)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c302f001598ec08c4a32518560827a418d5a50da"
      },
      "cell_type": "markdown",
      "source": "**Load the weights originally provided by YOLO**"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:30.966150Z",
          "start_time": "2017-11-30T13:01:30.224817Z"
        },
        "trusted": true,
        "_uuid": "e62c282783d27f909c91acb27a6193bcd2a98d99"
      },
      "cell_type": "code",
      "source": "weight_reader = WeightReader(wt_path)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:36.321111Z",
          "start_time": "2017-11-30T13:01:32.549255Z"
        },
        "trusted": true,
        "_uuid": "e8f84851328574d8409a31619a5636eae80e4006"
      },
      "cell_type": "code",
      "source": "weight_reader.reset()\nnb_conv = 23\n\nfor i in range(1, nb_conv+1):\n    conv_layer = model.get_layer('conv_' + str(i))\n    \n    if i < nb_conv:\n        norm_layer = model.get_layer('norm_' + str(i))\n        \n        size = np.prod(norm_layer.get_weights()[0].shape)\n\n        beta  = weight_reader.read_bytes(size)\n        gamma = weight_reader.read_bytes(size)\n        mean  = weight_reader.read_bytes(size)\n        var   = weight_reader.read_bytes(size)\n\n        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n        \n    if len(conv_layer.get_weights()) > 1:\n        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n        kernel = kernel.transpose([2,3,1,0])\n        conv_layer.set_weights([kernel, bias])\n    else:\n        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n        kernel = kernel.transpose([2,3,1,0])\n        conv_layer.set_weights([kernel])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "30394677f722d17c5dc212c4cec3d89a6be631d3"
      },
      "cell_type": "markdown",
      "source": "**Randomize weights of the last layer**"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:39.896045Z",
          "start_time": "2017-11-30T13:01:39.885562Z"
        },
        "trusted": true,
        "_uuid": "b3c282bc9a14cbc04bf06d8b65073064b4b8e043"
      },
      "cell_type": "code",
      "source": "layer = model.layers[-4] # the last convolutional layer\nweights = layer.get_weights()\n\nnew_kernel = np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W)\nnew_bias   = np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)\n\nlayer.set_weights([new_kernel, new_bias])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:57.936903Z",
          "start_time": "2017-11-30T13:01:57.691423Z"
        },
        "code_folding": [
          0
        ],
        "trusted": true,
        "_uuid": "d3dea14de84c3d5b0e6ee1bf4ae62a6f90cac9f3"
      },
      "cell_type": "code",
      "source": "def custom_loss(y_true, y_pred):\n    mask_shape = tf.shape(y_true)[:4]\n    \n    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n\n    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n    \n    coord_mask = tf.zeros(mask_shape)\n    conf_mask  = tf.zeros(mask_shape)\n    class_mask = tf.zeros(mask_shape)\n    \n    seen = tf.Variable(0.)\n    total_recall = tf.Variable(0.)\n    \n    \"\"\"\n    Adjust prediction\n    \"\"\"\n    ### adjust x and y      \n    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n    \n    ### adjust w and h\n    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n    \n    ### adjust confidence\n    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n    \n    ### adjust class probabilities\n    pred_box_class = y_pred[..., 5:]\n    \n\n    #Adjust ground truth\n    # adjust x and y\n    true_box_xy = y_true[..., 0:2] \n    \n    # adjust w and h\n    true_box_wh = y_true[..., 2:4]\n    \n    ### adjust confidence\n    true_wh_half = true_box_wh / 2.\n    true_mins    = true_box_xy - true_wh_half\n    true_maxes   = true_box_xy + true_wh_half\n    \n    pred_wh_half = pred_box_wh / 2.\n    pred_mins    = pred_box_xy - pred_wh_half\n    pred_maxes   = pred_box_xy + pred_wh_half       \n    \n    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n    \n    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n\n    union_areas = pred_areas + true_areas - intersect_areas\n    iou_scores  = tf.truediv(intersect_areas, union_areas)\n    \n    true_box_conf = iou_scores * y_true[..., 4]\n    \n    ### adjust class probabilities\n    true_box_class = tf.argmax(y_true[..., 5:], -1)\n    \n    # position of the ground truth boxes\n    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n    \n    # confidence mask\n    true_xy = true_boxes[..., 0:2]\n    true_wh = true_boxes[..., 2:4]\n    \n    true_wh_half = true_wh / 2.\n    true_mins    = true_xy - true_wh_half\n    true_maxes   = true_xy + true_wh_half\n    \n    pred_xy = tf.expand_dims(pred_box_xy, 4)\n    pred_wh = tf.expand_dims(pred_box_wh, 4)\n    \n    pred_wh_half = pred_wh / 2.\n    pred_mins    = pred_xy - pred_wh_half\n    pred_maxes   = pred_xy + pred_wh_half    \n    \n    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n    \n    true_areas = true_wh[..., 0] * true_wh[..., 1]\n    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n\n    union_areas = pred_areas + true_areas - intersect_areas\n    iou_scores  = tf.truediv(intersect_areas, union_areas)\n\n    best_ious = tf.reduce_max(iou_scores, axis=4)\n    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n    \n    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n    \n    ### class mask: simply the position of the ground truth boxes (the predictors)\n    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n    \n\n    #Warm-up training\n\n    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n    seen = tf.assign_add(seen, 1.)\n    \n    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n                                   tf.ones_like(coord_mask)],\n                          lambda: [true_box_xy, \n                                   true_box_wh,\n                                   coord_mask])\n    \n\n    #Finalize the loss\n    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n    \n    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n    \n    loss = loss_xy + loss_wh + loss_conf + loss_class\n    \n    nb_true_box = tf.reduce_sum(y_true[..., 4])\n    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n\n\n    # results\n  \n    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n    total_recall = tf.assign_add(total_recall, current_recall) \n\n    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n    \n    return loss",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4d2eea388d4a62dcbadbc7e16796f14bfad2c2d1"
      },
      "cell_type": "markdown",
      "source": "**start the training**"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-11-30T13:01:59.256666Z",
          "start_time": "2017-11-30T13:01:59.251294Z"
        },
        "code_folding": [],
        "trusted": true,
        "_uuid": "a452b2f231e1da770d0aa5042873b6699ae77520"
      },
      "cell_type": "code",
      "source": "early_stop = EarlyStopping(monitor='val_loss', \n                           min_delta=0.001, \n                           patience=3, \n                           mode='min', \n                           verbose=1)\n\ncheckpoint = ModelCheckpoint('weights_car.h5', \n                             monitor='val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='min', \n                             period=1)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.0001)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2017-11-30T21:02:03.460Z"
        },
        "scrolled": false,
        "trusted": true,
        "_uuid": "1dc768cd32e63180a9c1afe7dc730cd5c2110a97"
      },
      "cell_type": "code",
      "source": "optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n#optimizer = RMSprop(lr=1e-5, rho=0.9, epsilon=1e-08, decay=0.0)\n\nmodel.compile(loss=custom_loss, optimizer=optimizer)\n\nmodel.fit_generator(generator        = train_batch, \n                    steps_per_epoch  = len(train_batch), \n                    epochs           = 200, \n                    verbose          = 1,\n                    validation_data  = valid_batch,\n                    validation_steps = len(valid_batch),\n                    callbacks        = [reduce_lr,checkpoint])\nmodel.save('blood200E.h5')\n\n#model.train\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Adam' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-35398275eeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#optimizer = RMSprop(lr=1e-5, rho=0.9, epsilon=1e-08, decay=0.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "5a9da81a25a546c0be8b8c69542a4433c0a8f919"
      },
      "cell_type": "markdown",
      "source": "# Perform detection on image"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-03T13:23:58.365880Z",
          "start_time": "2017-10-03T13:23:58.361755Z"
        },
        "trusted": true,
        "_uuid": "85d17530ef808a2357b48fc610653ff4016e02b0"
      },
      "cell_type": "code",
      "source": "model.save('blood.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4dcb61c61864113d411f3411d58e795a4b04bf61"
      },
      "cell_type": "code",
      "source": "!ls",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19ab224f86b83856f715560a6d5129476004cb44"
      },
      "cell_type": "code",
      "source": "#image = batches[0][0][0][0]\nimport tensorflow as tf\nfrom keras.models import load_model\nimport keras.losses\nkeras.losses.custom_loss = custom_loss\n\nbestModel = load_model('weights_car.h5', custom_objects={\"tf\": tf})\nbestModel.compile(loss=custom_loss, optimizer=optimizer)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-03T13:35:41.121582Z",
          "start_time": "2017-10-03T13:35:40.383198Z"
        },
        "scrolled": true,
        "trusted": true,
        "_uuid": "a44d8ea887c15fa5f4fb7b3764fe313210ae2e90"
      },
      "cell_type": "code",
      "source": "#31, 27, \ndummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\nimage = valid_batch[0][0][0][10]\n#cv2.imread('./2018-lexus-rc-300.jpg')\n#image = cv2.imread('/home/andy/data/coco/val2014/COCO_val2014_000000000196.jpg')\n#image = cv2.imread(all_imgs[train_valid_split:][28]['filename'])\n\nplt.figure(figsize=(10,10))\n\ninput_image = cv2.resize(image, (416, 416))\n\ninput_image = input_image[:,:,::-1]\ninput_image = np.expand_dims(input_image, 0)\n\nnetout = model.predict([input_image, dummy_array])\n\nboxes = decode_netout(netout[0], \n                      obj_threshold=0.5,\n                      nms_threshold=0.5,\n                      anchors=ANCHORS, \n                      nb_class=CLASS)\nimage = draw_boxes(image, boxes, labels=LABELS)\nplt.imshow(image[:,:,::-1]); plt.show()\n\nprint(boxes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b6875eba9246596742674d8527368271203074d7"
      },
      "cell_type": "code",
      "source": "labels=LABELS\nfor box in boxes:\n    print(labels[box.get_label()] + ' ' + str(box.get_score()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f52d6b0f29b11508fd64663f142ee412849334a"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "toc": {
      "nav_menu": {
        "height": "381px",
        "width": "251px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "threshold": 4,
      "toc_cell": false,
      "toc_position": {
        "height": "714px",
        "left": "0px",
        "right": "1096px",
        "top": "76px",
        "width": "254px"
      },
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}